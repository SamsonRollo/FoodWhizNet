There has been already a wide variety of food classification studies that utilized various features and models. It is in this chapter that these related works of literature are reviewed about the proposed study. This chapter will include pieces of literature about existing food classification systems with deep learning and color spaces. 

%food classification, siamese, and cnn rrl
Zhou et al.\cite{zhou-2019} provide a review of several studies that utilized deep learning in food classification problems. It also includes a discussion about deep learning and its conception of food classification analysis. He concluded that there is a huge impact on the introduction of deep learning to food research because it revolutionizes as well as produces a robust and accurate approach to food classification. Despite the challenges that food classification can pose such as that presented by Ciocca et al. \cite{ciocca-2019} that food analysis is a difficult task due to the intrinsic high and low intra-class variability of the food segment. 

Focusing on the literature related to the food classification system, Vijayakumari et al. \cite{vijayakumari-2022} and Islam et al. \cite{islam-2018} focus on the use of transfer learning of a single CNN. Particularly \cite{vijayakumari-2022} utilized the EfficientNetB0 model and transformed it into a problem-dependent model based on the Food101 \cite{bossard-2014} dataset. While \cite{islam-2018} utilized the Inception V3 base model for transfer learning using the Food-11. Transfer learning freezes most of the layers except the top layer. This utilizes the pre-trained weights that the model has. In the case of these two studies, they were based on the ImageNet. This can be very helpful if the input image does not undergo color space conversion considering the the pretrained weights were in RGB therefore the problem-dependent task matches the problem-independent requirements. 

In Vijayakumari et al. \cite{vijayakumari-2022} conduct of study, they have proposed the use of EfficientNetB0 as a source for their transfer learning. Starting from the problem-independent pre-trained model EfficientNetB0, they have extended the model by adding their problem-dependent network used for fine-tuning EffiecientNetB0's feature maps. The structure is similar to the naive CNN with another set of networks connected after each pooling layer. Also, they noted that the use of a rectified linear unit was in effect for the nonlinear activation operation. The proposed model consists of four methods, all have the EfficientNetB0 as the CNN, input size of 224x224, data augmentation technique of horizontal flipping and rotation, pooling using the global average pooling 2d, loss function of categorical cross-entropy, and ran a 100 epoch. Model 3 and 4 has a mixed float 16 for the mixed precision parameter. Models 1 and 3 have a learning rate of 1e\textsuperscript{-2}, while Models 2 and 4 have a learning rate of 1e\textsuperscript{-4}. They have used the Food-101 dataset \cite{bossard-2014} with a 75-25 train-test split. The results were analyzed according to the precision, recall, and f1-score. Among their four proposed methods, Model 4 has the highest score with more than 80\% across all three metrics. They have also surpassed their predecessor's accuracy. 

Another transfer learning study on food classification that was mentioned was on Islam et al. \cite{islam-2018}. Recognizing the challenging task of the food classification problem due to its non-linearity, they have proposed a CNN model using transfer learning with Inception V3 which is pre-trained with ImageNet. To address their hardware resource limitation, they have used the Food-11 dataset which contains 16643 images with 11 classes. In their experimental setup, they utilized an 80-10-10 train-validation-test split. The same with most image classification systems, they have conducted image preprocessing to lessen the training time. Specific to their experiment is the use of the ZCA whitening reduction method which reduces the redundant image pixels to emphasize more the features of the image. They have also set the dimension of the input image specific to the model they are using, the 299 x 299 x 3 dimension. The result of the study shows a staggering 92.86\%, outperforming fine-tuned AlexNet by 10.63\% and CaffeNet by 12.84\%.

An additional food classification system approach is the use of multiple parallel Convolutional Neural Networks. The study of Pandey et al \cite{pandey-2017}, Martinel et al. \cite{martinel-2018}, and Al-Sarayreh et al. \cite{al-sarayreh-2018} utilized the power of different base models ran in parallel to exploit its strength to mine discriminative features. These parallel CNNs are not necessarily the same since they want to make the best out of a particular pre-trained model. For instance, Martinel et al. \cite{martinel-2018}, have used two networks in parallel, one is a pre-trained ResNet to capture all the generic features and one is for capturing the vertical features of food images. The use of multiple parallel CNNs has shown its efficient performance in classification tasks. Moreover, another set of studies that focuses on the use of multiple parallel CNNs is that of fake image detection tasks such as He et al. \cite{he-2019} and Larbi et al. \cite{larbi-2018}.

Expounding Pandey et al.\cite{pandey-2017}, a food classification system was developed to address its predecessors' accuracy and robustness concerns while considering the intra-class variability characteristic of the food classification problem. By utilizing both the Food-101 dataset\cite{bossard-2014} and a novel Indian food dataset, they have proposed to create an ensemble of multiple layered CNN pipelines. Using AlexNet as the baseline architecture for the proposed model and the Siamese CNN structure, they have devised a 3-layered pipeline with AlexNet, GoogleNet, and ResNet as its sub-networks. The authors believed that each of the sub-network's best characteristics would contribute to better classification accuracy. Similar to most image classification systems, images are first preprocessed to be fed to the model. For the Food-101 dataset, RGB images were first converted to HSV for proper histogram equalization before converting back to RGB for processing. They have set the maximum side length to 512 pixels and used the 75-25 train-test split. A different approach was done on the local dataset where minimum size was ensured and no maximum size was enforced. They also used 80-20 train-test splits for this particular dataset. They have conducted their experiments using handcrafted features and CNN feature descriptors. The study produced a promising output with 73.50\%, 94.40\%, and 97.60\% for Top-1\%, Top-5\%, and Top-10\%, respectively on the Indian food dataset which is much higher than each of the individual sub-network's accuracy. It also has a higher accuracy using the Food-101 dataset with 72.12\%, 91.61\%, and 95.95\% for Top-1\%, Top-5\%, and Top-10\%, respectively.

%martinel, 2018
Also in Martinel et al. \cite{martinel-2018} a novel approach was developed to food recognition using a combination of slice network with slice convolution layer and residual network. This study is included in the review since it includes food classification. One of the networks is the wide residual network which is a pre-trained model through ImageNet 2012 and the other is the slice network which is in naive implementation from scratch, proposing the WISeR model, a combination of the two sub-networks. Their slice sub-network was used to capture and exploit the vertical features of the food images because one of their hypothesis was that many of the dishes from the dataset are characterized by so. In the wide residual sub-network, they have followed the use of a series of batch normalization and rectified linear units for preactivation for their CNN as well as increasing their feature map size as it progresses along the sub-network addressing the diminishing feature problem and capturing the rest of the generic features that haven't been captured by the slice sub-network. The datasets used were the UECFood100 \cite{matsuda-2012}, UECFood256 \cite{kawano-2014,kawano-2015}, and Food-101 dataset \cite{bossard-2014}. In their Food-101 dataset, the 75-25 train-test split was used. They have evened out the learning rate for the slice sub-network to match it with the existing units created by the wide residual sub-network, as well as fine-tuning the model by taking 224 x 224 images and conducting data augmentation techniques such as horizontal flipping, aspect ratio augmentation, photometric distortions, and alexNet-style color augmentations. Running a total of 100k iterations with an initial learning rate of 0.01 updating to 0.002 after 50k iterations to 0.0004 after 90k iterations with constant weight decay of 0.0005 and 0.9 momentum for all layers.  Overall, the proposed WISeR model outperforms the existing models in the food recognition problem, resulting in 90.27\% Top-1\% and 98.71\% for the Top-5\%. Their study also found that the use of the pre-trained model outperforms new models supporting the claim of Vijayakumari et al.\cite{vijayakumari-2022}. This was done on their ablation analysis on each sub-network. For the three datasets, the wide residual network outperforms the slice convolution network.

Another study on multiple parallel CNN and spectral input is Al-Sarayreh et al. \cite{al-sarayreh-2018} who conducted a study on red-meat adulteration using spectral and spatial features. Using hyperspectral imaging, they extracted their dataset from collected meat from various sources as a hyperspectral cube with dimensions \textit{w} x \textit{l} x \textit{g}, where \textit{w} is the width, \textit{l} is the length, and \textit{g} is the intensity of the reflected light. With 75 samples, the study follows a 76-24 train-test split with six calibrations, four sets of collected samples, and three classes. The calibrations were fresh red meat unpacked, freshly packed, frozen unpacked, frozen packed, frozen-thawed unpacked, and the ground truth. The four samples were lamb, beef, pork, and fat. The samples are divided into three classes, LAMB class for lamb samples, FAT class for fat samples, and OTHER class for beef and pork samples. The proposed model has the same structure as the Siamese CNN but has an unbalanced sub-networks. Since they take two inputs, the spectral and spatial features, each input is processed differently, such that spectral input is fed to a 1D CNN utilizing the mean spectrum extracted from the HSI using the Kennard-Stone algorithm when sampling the superpixels. Superpixels were generated using the SLIC superpixel algorithm. They have noted that to have the spatial feature input which was fed on a 3D CNN, they have used PCA space over the SLIC superpixel to match the spectral input. They have also conducted a preprocessing of the spectral input by utilizing the Savitsky-Golay algorithm to normalize it by smoothing and de-spiking. The proposed model was trained using forward propagation and back propagation. For each layer, the output feature is concatenated and undergoes the same process until the very end where the output is defined using the softmax activation function. For the back propagation, stochastic gradient descent was used with a categorical focal loss function. To address the overfitting issue, they have enforced regularization and dropout techniques. The setup was given by running 500 epochs with a 0.003 learning rate, momentum of 0.9, and a rectified linear unit on the hidden layers. Overall, they analyzed the experiment using the f1-score and overall accuracy. Outperforming the conventional SVM spectral-based and SVM spatial-based models, at 94.4\% accuracy. Although performing last among the three, the SVM spectral-based model still achieves an overall accuracy of 91.4\%.

To discuss the use of multiple color space input, related studies are also presented such as in Larbi et al. \cite{larbi-2018} who conducted a study on the efficiency of using multi-color CNN on Face Spoofing detection. The same goes with He et al.\cite{he-2019} where the use of multiple color spaces on the GAN-generated images was used. Furthermore, Gowda and Yuan \cite{gowda-2019} test the effectiveness of using different color spaces on image classification using the CIFAR dataset.

In Larbi et al. \cite{larbi-2018}, they used the three color spaces; RGB, HSV, and YCbCr, as an input to each of the three identical CNN models. The selection process was done using a voting mechanism. The extraction sequence of the color space affects the generation of histograms therefore creating a noticeable difference between the real and fake face.

Moreover, He et al. \cite{he-2019} also conducted a study on fake image detection made by GAN techniques using CNN with an RF ensemble. They focused mainly on the use of chrominance components from HSV, YCbCr, and Lab for robust detection in detecting fake images. Similar to \cite{larbi-2018}, the proposed methodology utilized three identical CNNs but differed in the input for each model, and the depth of the model. It was mentioned that YCbCr is good for lossy compression of digital images, and HSV is best applied on computer vision tasks.

Gowda and Yuan \cite{gowda-2019} investigated the importance of color spaces in image classification. Their study opened a new challenge to the current study concerning data profiling. They mentioned the existence of sRGB from the CIFAR dataset which may affect the feature extraction of the proposed study if any images have the same image format from the Food-101 dataset \cite{bossard-2014}. Additionally, they have mentioned some of the popular color spaces including HSV, lab, YUV, YCbCr, XYZ, YIQ, HED, LCH, and CMYK. For which combining color spaces can increase the accuracy of image classification algorithms. They also reasoned out that certain color space is appropriate to certain classification problems.  In consideration of the two-input model, their study produced a table where the combination of YUV and LAB color spaces produced the highest accuracy from their selected color spaces on the CIFAR-10 dataset with a simple CNN model. The use of LCH, YPbPr, and XYZ color spaces degraded the overall accuracy of their model, therefore discarding it. The use of RGB, YIQ, LAB, HSV, YUV, YCbCr, and HED were recommended to produce high accuracy in image classification problems.

In support of the previously reviewed study, Kang \cite{kang-2011} also suggested the use of CIELab or LAB color space in evaluating food images. The ability of LAB color space to detect color changes and differences is attributed to its absolute measurement, therefore disregarding any lighting effect on the image. Markovic \cite{markovic2013color} also suggested the use of LAB and RGB color space combinations in food quality evaluation. 

% conclusion
 In relation to the currently proposed study, similarities can be seen from the reviewed works of literature. In consideration of the use of multiple inputs, \cite{al-sarayreh-2018, martinel-2018, pandey-2017} has paved the way by introducing multilayered CNN pipelines with different sub-networks. The only difference is that instead of deviating from the Siamese structure, this study will be using the Siamese CNN as a baseline conforming to balanced sub-networks. The utilization of pre-trained models was also considered since from the reviews, they have a huge impact on the accuracy such that on the study of \cite{al-sarayreh-2018,martinel-2018,vijayakumari-2022}. The effectiveness and high accuracy of the spectral feature \cite{al-sarayreh-2018} of the image such as the color as an input to deep learning also drive the use of color spaces as the primary input to the proposed study. In order to address the need for multiple inputs such as in Siamese CNN, a variety of color spaces is utilized and the selection of color will solely be based on the literature, focusing on a combination of LAB color space and others. 