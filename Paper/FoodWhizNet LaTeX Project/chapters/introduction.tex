Food is essential to humans in order to survive, situated at the bottom of the hierarchy of needs by Maslow \cite{Mcleod2023} together with shelter and clothes. The task of classifying them accordingly benefits not only personal gain but also the professional field, for instance, the medical science and nutrition field where multiple uses include diet planning \cite{chun-2022, de-kervenoael-2023,zhou-2019}. It is becoming one of the wake-up calls for most people to live a healthy lifestyle after the COVID-19 pandemic. Being able to know what food you are eating is the best way to start living healthy. Classifying the foods you are eating is sometimes not an easy task especially since there are plenty of foods available worldwide. Food classification does not stop on personal use only. The science community benefits from this also as this becomes a way for most improvements to models and algorithms in various problems, for instance in classification problems.

With the rise of Artificial Intelligence and the Internet of Things marking the fourth industrial revolution \cite{sarker-2021}, the aim to automate food classification is also popularized. With the advent of Deep Learning and its variant architectures such as Convolutional Neural Networks \cite{lecun-2015,shrestha-2019} comes with the task of creating a robust and effective model to cater to the needs of going together in the tides of technology.

To utilize the power of deep learning, this study aims to create a robust and effective model that utilizes multiple variations of a single feature, the color, to be fed on a Siamese CNN model pre-trained with EfficientNetB0. Thus, this study is titled \textit{FoodWhizNet: A Web-based Food Classification System using Multi-Color Space Siamese-CNN Model}.

This paper is organized accordingly. Part 1 is the Introduction containing Section 1.1 which provides a background of the study together with the terms and concepts relevant to the food image classification problem. Part 2 provides an elaborate review of related literature. Part 3 indicates the research gap and problem that this study aims to address. Part 4 defines both the general and specific objectives of the study. Part 5 for the scope and limitation, Part 6 covers the significance of the study, and Part 7 addresses both the theoretical and conceptual frameworks. Part 8 focuses on the discussion of the proposed tools and methods. Part 9 provides the initial gathered results from the initial experiments. Part 10 highlights schedule of activities for this study.  
\section{Background of the Study}
\subsection{Food Classification}
Food classification can have its benefits to either professional sectors or for personal gain. May it be for creating a diet plan for a healthy lifestyle or may it be for traveling abroad to familiarize yourself with novel foods. In consideration of the number of food classes around the world, the complexity to which a single food can be classified also increases. This is because the food classification problem has a unique characteristic for it to be a difficult task to go with. This is its high and low intra-class variability \cite{ciocca-2019} and non-linearity \cite{islam-2018} so classifying food class accordingly always came with a caveat. In the conduct of various studies with regards to food classification, some of the most common datasets include the Food-101 \cite{bossard-2014}, UECFood100 \cite{matsuda-2012}, and UECFood256 \cite{kawano-2014,kawano-2015}. These datasets were also used for benchmarking the models created from either machine learning or deep learning. Other studies conducted on food classification create their dataset such as that of \cite{pandey-2017} for localization of the learned model.
\subsection{Deep Learning and CNN}
As artificial intelligence advances, new fields are being unlocked to address the weaknesses of the current fields. The introduction of deep learning as a subset of machine learning gave way to a more sophisticated yet robust way of learning things without almost human intervention in the preparation of data. Deep learning as mentioned in Lecun et al. \cite{lecun-2015} is a way to make models learn the features and representation of the input on their own by conducting its own feature extraction and analyzing the representation through the multiple layers of the model with minimal external intervention. The conception of deep learning has also brought to us the robustness and increase in productivity as well as the accuracy of the task to be conducted. Shrestha and Mahmood \cite{shrestha-2019} conducted a review on deep learning and its architecture. Deep learning architectures include deep residual networks, reinforcement learning, deep convolution networks, autoenconders, and more. This study will be utilizing a Convolutional Neural Network or CNN due to its appropriateness to image classification \cite{sarker-2021} so it will be mentioned more. CNN is one of the most common architectures of the Deep Neural Network (DNN) that utilizes multiple layers of representation and concatenates the layer output at the end to have a defined output. As part of the DNN, CNN also faces two major challenges such as overfitting, premature convergence, vanishing gradient, exploding gradient, training time, and more \cite{shrestha-2019}. In order to address these issues, one should be aware of these challenges and the set of solutions provided as well as the use of appropriate parameters for the model.
\subsection{Siamese Convolutional Neural Networks}
Siamese Convolutional Neural Network or SCNN is a variation of CNN that contains two identical sub-networks \cite{prasad-2021}. The sub-networks have similar parameters and architecture. This particular type of CNN is best used for checking the similarity or dissimilarity of two inputs. Due to its robust characteristic of classifying similarity between two images, it is effective in steganalysis \cite{you-2021}. SCNN is also best used with fingerprint matching and face verification tasks. SCNN application on food classification can also be seen in \cite{sarker-2019} where the one-shot learning was exploited. In this study, SCNN will be utilized to record the similarity index of the spectral feature extracted from the food image. The structure of Siamese CNN also inspired some of the Multiple layered CNN pipelines such as \cite{martinel-2018, pandey-2017}.
\subsection{Pre-trained CNN Models}
Pre-trained CNN models are those models that have already undergone the process of training and already have defined weights. Yalcin \cite{yalcn-2021} discussed the notion of transfer learning and its uses. Basically, transfer learning uses pre-trained models to alleviate the costly training process of novel or similar models. Existing models such as VGG-19 \cite{simonyan2015deep} used for image classification problems \cite{bansal-2021} was a 19-layer deep CNN trained using an ImageNet database with more than a million images and over 140M parameters. This model was trained using 224 x 224 image dimensions and can classify for up to a thousand classes. Another pre-trained model is the InceptionV3 \cite{Szegedy_2015_CVPR} which was developed by Google and was also trained using the ImageNet with an image dimension of 299 x 299 and over 20M parameters. It has a depth of about 50 layers and can classify up to a thousand classes. ResNet50 \cite{He_2016_CVPR} or the Residual Network is also one of the pre-trained models used for transfer learning. It was also trained using the ImageNet database with over a million 224 x 224 sized images with a depth of 50 layers and over 20M parameters. This too can classify over a thousand classes. Another popular pre-trained model is the EfficientNet \cite{pmlr-v97-tan19a} which has 8 variations (from B0 to B7). Even the simplest B0, having over 5M parameters can achieve satisfactory accuracy, whereas B7 has over 60M parameters with greater accuracy compared to other pre-trained models at such low parameters. MobileNet \cite{howard2017mobilenets} being the smallest pre-trained model with 4M parameters on its baseline and 3M parameters on its V2 and a depth for both of 88 layers. Despite its small size, it can still satisfactorily classify objects, perfect for conducting initial experiments on novel or hybrid models.
\subsection{Multi-Color Space}
The importance of color can be related to its effect on the sense of sight as according to Fries \cite{grusser-1989}, the sense of sight is the window that takes us beyond and apprehends everything that our sight could perceive including colors. Its importance is not limited to humans alone but it also creates a huge impact in the image analysis carried out by artificial intelligence, such as that of deep learning \cite{larbi-2018,he-2019,hirota-2020}. Its utilization as a spectral feature for deep learning such as in \cite{al-sarayreh-2018} can result in a satisfactory accuracy but not better than other features, or combinations as such. To address the satisfactory performance of using single colors in conducting image analysis, the use of multiple color spaces as input can be utilized as different color spaces correspond to different conditions such as lighting and noise. There are already studies in relation to the use of multiple color spaces, one is from Gowda and Yuan \cite{gowda-2019} which suggests that there is a right color space for certain image classes and that combination of certain color spaces can improve accuracy for certain image analysis problem. The most common color space that is utilized for most image classification problems is the RGB which contains the Red, Green, and Blue color channels. Each channel has values ranging from 0 to 255. Machine Learning defaults to the use of RGB color space unless specific tasks require other color space to be used.  Another commonly used color space is the HSV which contains the Hue, Saturation, and Value channels. Its channel has values ranging from 0 to 360 for Hue, and 0 to 100 for both Saturation and Value channels. HSV is useful in image identification as it can segment better the objects in an image \cite{sural-2003}. More color spaces exist like the LAB which is based on the Lightness and RGBY colors, the YPbPr, YCbCr, YDbDr, YUV, XYZ, etc.